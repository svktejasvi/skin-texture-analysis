{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE MODEL AND MARK LABELS ON THE FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('../model/model1.h5')  # <-- Saved model path\n",
    "\n",
    "\n",
    "def detect_points(face_img):\n",
    "    me  = np.array(face_img)/255\n",
    "    x_test = np.expand_dims(me, axis=0)\n",
    "    x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "    y_test = model.predict(x_test)\n",
    "    label_points = (np.squeeze(y_test)*48)+48 \n",
    "    \n",
    "    return label_points\n",
    "    \n",
    "# Load haarcascade\n",
    "face_cascade = cv2.CascadeClassifier('../conf/opencv_haarcascade/haarcascade_frontalface_default.xml')\n",
    "dimensions = (96, 96)\n",
    "\n",
    "# Enter the path to your test image\n",
    "img = cv2.imread('../raw_images/Test_Image_1.JPG')\n",
    "\n",
    "default_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "# faces = face_cascade.detectMultiScale(gray_img, 4, 6)\n",
    "\n",
    "faces_img = np.copy(gray_img)\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "\n",
    "all_x_cords = []\n",
    "all_y_cords = []\n",
    "\n",
    "for i, (x,y,w,h) in enumerate(faces):\n",
    "    \n",
    "    h += 10\n",
    "    w += 10\n",
    "    x -= 5\n",
    "    y -= 5\n",
    "    \n",
    "    just_face = cv2.resize(gray_img[y:y+h,x:x+w], dimensions)\n",
    "    cv2.rectangle(faces_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "    \n",
    "    scale_val_x = w/96\n",
    "    scale_val_y = h/96\n",
    "    \n",
    "    label_point = detect_points(just_face)\n",
    "    all_x_cords.append((label_point[::2]*scale_val_x)+x)\n",
    "    all_y_cords.append((label_point[1::2]*scale_val_y)+y)\n",
    "   \n",
    "   \n",
    "    plt.imshow(just_face, cmap='gray')\n",
    "    plt.plot(label_point[::2], label_point[1::2], 'ro', markersize=5)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plt.imshow(default_img)    \n",
    "plt.plot(all_x_cords, all_y_cords, 'wo',  markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MASK EYES AND MOUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_eye_pts = np.array([[all_x_cords[0][2],all_y_cords[0][2]+10],[all_x_cords[0][0],all_y_cords[0][0]+10],[all_x_cords[0][3],all_y_cords[0][3]+10],[all_x_cords[0][7],all_y_cords[0][7]+10],[all_x_cords[0][6],all_y_cords[0][6]+10]], np.int32)\n",
    "lt_eye_pts = np.array([[all_x_cords[0][1],all_y_cords[0][1]+10],[all_x_cords[0][5],all_y_cords[0][5]+10],[all_x_cords[0][9],all_y_cords[0][9]+10],[all_x_cords[0][8],all_y_cords[0][8]+10],[all_x_cords[0][4],all_y_cords[0][4]+10]], np.int32)\n",
    "mth_pts = np.array([[all_x_cords[0][10],all_y_cords[0][10]-10],[all_x_cords[0][12],all_y_cords[0][12]-10],[all_x_cords[0][11],all_y_cords[0][11]-10],[all_x_cords[0][13],all_y_cords[0][13]-10]], np.int32)\n",
    "masked_img = cv2.fillPoly(default_img, [rt_eye_pts], 255)\n",
    "masked_img = cv2.fillPoly(masked_img, [lt_eye_pts], 255)\n",
    "masked_img = cv2.fillPoly(masked_img, [mth_pts], 255)\n",
    "plt.imshow(masked_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
