{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFPOQDJvuWT0"
   },
   "outputs": [],
   "source": [
    "# RUN THIS ONLY IF YOU ARE IN GOOGLE COLAB NOTEBOOK\n",
    "!ls\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "import os\n",
    "os.chdir(\"drive/folder_name_where_this_file_is_saved\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBnD3V2CuaD5"
   },
   "outputs": [],
   "source": [
    "#####  LOADING AND EXTRACTING DATA   #####\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def data_loader():\n",
    "    \n",
    "    # Load dataset file\n",
    "    data_frame = pd.read_csv('training.csv')\n",
    "    \n",
    "    data_frame['Image'] = data_frame['Image'].apply(lambda i: np.fromstring(i, sep=' '))\n",
    "    data_frame = data_frame.dropna()  # Get only the data with 15 keypoints\n",
    "   \n",
    "    # Extract Images pixel values\n",
    "    imgs_array = np.vstack(data_frame['Image'].values)/ 255.0\n",
    "    imgs_array = imgs_array.astype(np.float32)    # Normalize, target values to (0, 1)\n",
    "    imgs_array = imgs_array.reshape(-1, 96, 96, 1)\n",
    "        \n",
    "    # Extract labels (key point cords)\n",
    "    labels_array = data_frame[data_frame.columns[:-1]].values\n",
    "    labels_array = (labels_array - 48) / 48    # Normalize, traget cordinates to (-1, 1)\n",
    "    labels_array = labels_array.astype(np.float32) \n",
    "    \n",
    "    # shuffle the train data\n",
    "#     imgs_array, labels_array = shuffle(imgs_array, labels_array, random_state=9)  \n",
    "    \n",
    "    return imgs_array, labels_array\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# # This snippet is just to check/verify data\n",
    "# imgs, labels = data_loader()\n",
    "# print(imgs.shape)\n",
    "# print(labels.shape)\n",
    "\n",
    "# n=0\n",
    "# labels[n] = (labels[n]*48)+48\n",
    "# image = np.squeeze(imgs[n])\n",
    "# plt.imshow(image, cmap='gray')\n",
    "# plt.plot(labels[n][::2], labels[n][1::2], 'ro')\n",
    "# plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_mj1zTvuwue"
   },
   "outputs": [],
   "source": [
    "######   BUILD, TRAIN AND SAVE THE CONVOLUTIONAL MODEL    ########\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Activation\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Main model\n",
    "def the_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=X_train.shape[1:])) # Input shape: (96, 96, 1)\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # Convert all values to 1D array\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(30))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "X_train, y_train = data_loader()\n",
    "print(\"Training datapoint shape: X_train.shape:{}\".format(X_train.shape))\n",
    "print(\"Training labels shape: y_train.shape:{}\".format(y_train.shape))\n",
    "\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 64\n",
    "\n",
    "model = the_model()\n",
    "hist = History()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoint1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Complie Model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model_fit = model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist], verbose=1)\n",
    "\n",
    "model.save('model1.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzUVeVykvF6f"
   },
   "outputs": [],
   "source": [
    "#####  TEST YOUR IMAGE FILE WITH THE MODEL  #####\n",
    "\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('model1.h5')  # <-- Saved model path\n",
    "\n",
    "\n",
    "def detect_points(face_img):\n",
    "    me  = np.array(face_img)/255\n",
    "    x_test = np.expand_dims(me, axis=0)\n",
    "    x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "    y_test = model.predict(x_test)\n",
    "    label_points = (np.squeeze(y_test)*48)+48 \n",
    "    \n",
    "    return label_points\n",
    "    \n",
    "# Load haarcascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "dimensions = (96, 96)\n",
    "\n",
    "# Enter the path to your test image\n",
    "img = cv2.imread('you_test_image.jpg')\n",
    "\n",
    "default_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "# faces = face_cascade.detectMultiScale(gray_img, 4, 6)\n",
    "\n",
    "faces_img = np.copy(gray_img)\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "\n",
    "all_x_cords = []\n",
    "all_y_cords = []\n",
    "\n",
    "for i, (x,y,w,h) in enumerate(faces):\n",
    "    \n",
    "    h += 10\n",
    "    w += 10\n",
    "    x -= 5\n",
    "    y -= 5\n",
    "    \n",
    "    just_face = cv2.resize(gray_img[y:y+h,x:x+w], dimensions)\n",
    "    cv2.rectangle(faces_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "    \n",
    "    scale_val_x = w/96\n",
    "    scale_val_y = h/96\n",
    "    \n",
    "    label_point = detect_points(just_face)\n",
    "    all_x_cords.append((label_point[::2]*scale_val_x)+x)\n",
    "    all_y_cords.append((label_point[1::2]*scale_val_y)+y)\n",
    "   \n",
    "   \n",
    "    plt.imshow(just_face, cmap='gray')\n",
    "    plt.plot(label_point[::2], label_point[1::2], 'ro', markersize=5)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plt.imshow(default_img)    \n",
    "plt.plot(all_x_cords, all_y_cords, 'wo',  markersize=3)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9PJngooxW2f"
   },
   "outputs": [],
   "source": [
    "####  TEST YOUR VIDEO FILE WITH THE MODEL  #####\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "model = load_model('model1.h5')  # <-- Saved model path\n",
    "\n",
    "\n",
    "# input video file path\n",
    "input_file = 'testVideo.mp4'\n",
    "\n",
    "\n",
    "# output file path\n",
    "output_filename = 'testVideo_out.avi'  \n",
    "\n",
    "\n",
    "def get_points_main(img):\n",
    "\n",
    "    def detect_points(face_img):\n",
    "        me  = np.array(face_img)/255\n",
    "        x_test = np.expand_dims(me, axis=0)\n",
    "        x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "        y_test = model.predict(x_test)\n",
    "        label_points = (np.squeeze(y_test)*48)+48\n",
    "\n",
    "\n",
    "        return label_points\n",
    "\n",
    "    # load haarcascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    dimensions = (96, 96)\n",
    "\n",
    "\n",
    "    try:\n",
    "        default_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray_img = cv2.cvtColor(default_img, cv2.COLOR_RGB2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "#         faces = face_cascade.detectMultiScale(gray_img, 4, 6)\n",
    "\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    faces_img = np.copy(gray_img)\n",
    "\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "\n",
    "    all_x_cords = []\n",
    "    all_y_cords = []\n",
    "\n",
    "\n",
    "    for i, (x,y,w,h) in enumerate(faces):\n",
    "\n",
    "        h += 10\n",
    "        w += 10\n",
    "        x -= 5\n",
    "        y -= 5\n",
    "\n",
    "        try:\n",
    "            just_face = cv2.resize(gray_img[y:y+h,x:x+w], dimensions)\n",
    "        except:\n",
    "            return []\n",
    "        cv2.rectangle(faces_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "\n",
    "        scale_val_x = w/96\n",
    "        scale_val_y = h/96\n",
    "\n",
    "        label_point = detect_points(just_face)\n",
    "\n",
    "        all_x_cords.append((label_point[::2]*scale_val_x)+x)\n",
    "        all_y_cords.append((label_point[1::2]*scale_val_y)+y)\n",
    "\n",
    "\n",
    "\n",
    "    final_points_list = []\n",
    "    try:\n",
    "        for ii in range(len(all_x_cords)):\n",
    "            for a_x, a_y in zip(all_x_cords[ii], all_y_cords[ii]):\n",
    "                final_points_list.append([a_x, a_y])\n",
    "    except:\n",
    "        return final_points_list\n",
    "\n",
    "    return final_points_list\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "ret, frame = cap.read()\n",
    "height, width, channel = frame.shape\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter(output_filename, fourcc, 20.0, (width, height))\n",
    "\n",
    "\n",
    "frame_no = 0\n",
    "while cap.isOpened():\n",
    "\n",
    "    a = time.time()\n",
    "    \n",
    "    frame_no += 1\n",
    "    ret, frame = cap.read()\n",
    "    if frame_no > 75*30:\n",
    "        break\n",
    "    if frame_no in range(60*30, 75*30):\n",
    "        points = get_points_main(frame)\n",
    "\n",
    "        try:\n",
    "            overlay = frame.copy()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "        for point in points:\n",
    "\n",
    "            cv2.circle(frame, tuple(point), 3, (255, 255, 255), -1)\n",
    "            # cv2.line(frame, last_point, tuple(point), (0,0,255), thickness=1)\n",
    "            # cv2.putText(overlay, str(i), tuple(point), 1, 1, (255, 255, 255))\n",
    "\n",
    "        if len(points) != 0:\n",
    "            o_line_points = [[12,13], [13,11], [11,14], [14,12], [12,10], [11,10], [10,3], [12,5], [11,3], [10,5], [10,4], [10,2], [5,1], [1,4], [2,0], [0,3], [5,9], [9,8], [8,4], [2,6], [6,7], [7,3]]\n",
    "            num_face = len(points)//15\n",
    "\n",
    "            for i in range(num_face):\n",
    "                line_points = np.array(o_line_points) + (15*(i))\n",
    "\n",
    "                the_color = (189, 195, 199)\n",
    "\n",
    "                for ii in line_points:\n",
    "                    cv2.line(overlay, tuple(points[ii[0]]), tuple(points[ii[1]]), the_color, thickness=1)\n",
    "\n",
    "\n",
    "        opacity = 0.3\n",
    "        cv2.addWeighted(overlay, opacity, frame, 1 - opacity, 0, frame)\n",
    "\n",
    "        out.write(frame)\n",
    "        # cv2.imshow('frame',frame)\n",
    "        b = time.time()\n",
    "        print(str((b-a)))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "           \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOAUDoeHzdpT"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For more details watch >> https://www.youtube.com/watch?v=vC3bTziLRTA\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "facialKeypointDetection_YT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
